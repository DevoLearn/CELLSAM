{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q monai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-04T04:58:51.334199Z","iopub.execute_input":"2023-10-04T04:58:51.335169Z","iopub.status.idle":"2023-10-04T04:59:04.709661Z","shell.execute_reply.started":"2023-10-04T04:58:51.335133Z","shell.execute_reply":"2023-10-04T04:59:04.708344Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone -b batch_size https://github.com/sushmanthreddy/segment-anything.git","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:04.712043Z","iopub.execute_input":"2023-10-04T04:59:04.712421Z","iopub.status.idle":"2023-10-04T04:59:07.943220Z","shell.execute_reply.started":"2023-10-04T04:59:04.712385Z","shell.execute_reply":"2023-10-04T04:59:07.941952Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'segment-anything'...\nremote: Enumerating objects: 306, done.\u001b[K\nremote: Counting objects: 100% (172/172), done.\u001b[K\nremote: Compressing objects: 100% (56/56), done.\u001b[K\nremote: Total 306 (delta 131), reused 116 (delta 116), pack-reused 134\u001b[K\nReceiving objects: 100% (306/306), 18.31 MiB | 22.58 MiB/s, done.\nResolving deltas: 100% (165/165), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd segment-anything/\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:07.945591Z","iopub.execute_input":"2023-10-04T04:59:07.946053Z","iopub.status.idle":"2023-10-04T04:59:07.954151Z","shell.execute_reply.started":"2023-10-04T04:59:07.945990Z","shell.execute_reply":"2023-10-04T04:59:07.953060Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/segment-anything\n","output_type":"stream"}]},{"cell_type":"code","source":"ls -a\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:07.957452Z","iopub.execute_input":"2023-10-04T04:59:07.958261Z","iopub.status.idle":"2023-10-04T04:59:09.030688Z","shell.execute_reply.started":"2023-10-04T04:59:07.958226Z","shell.execute_reply":"2023-10-04T04:59:09.029466Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34m.\u001b[0m/       .gitignore          README.md   \u001b[01;34mnotebooks\u001b[0m/         setup.py\n\u001b[01;34m..\u001b[0m/      CODE_OF_CONDUCT.md  \u001b[01;34massets\u001b[0m/     \u001b[01;34mscripts\u001b[0m/\n.flake8  CONTRIBUTING.md     \u001b[01;34mdemo\u001b[0m/       \u001b[01;34msegment_anything\u001b[0m/\n\u001b[01;34m.git\u001b[0m/    LICENSE             \u001b[01;32mlinter.sh\u001b[0m*  setup.cfg\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:09.032809Z","iopub.execute_input":"2023-10-04T04:59:09.033242Z","iopub.status.idle":"2023-10-04T04:59:21.711564Z","shell.execute_reply.started":"2023-10-04T04:59:09.033202Z","shell.execute_reply":"2023-10-04T04:59:21.710370Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/segment-anything\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hInstalling collected packages: segment-anything\n  Attempting uninstall: segment-anything\n    Found existing installation: segment-anything 1.0\n    Uninstalling segment-anything-1.0:\n      Successfully uninstalled segment-anything-1.0\n  Running setup.py develop for segment-anything\nSuccessfully installed segment-anything-1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\njoin = os.path.join\nfrom tqdm import tqdm\nfrom skimage import transform\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport monai\nfrom segment_anything import sam_model_registry\nimport torch.nn.functional as F\nimport argparse\nimport random\nfrom datetime import datetime\nimport shutil\nimport glob\nfrom os import listdir\nfrom os.path import isfile, join\nimport pandas as pd\nfrom PIL import Image\n\n# set seeds\ntorch.manual_seed(2023)\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:21.713248Z","iopub.execute_input":"2023-10-04T04:59:21.713604Z","iopub.status.idle":"2023-10-04T04:59:58.293817Z","shell.execute_reply.started":"2023-10-04T04:59:21.713569Z","shell.execute_reply":"2023-10-04T04:59:58.292783Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd ..\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:58.295498Z","iopub.execute_input":"2023-10-04T04:59:58.296405Z","iopub.status.idle":"2023-10-04T04:59:58.305627Z","shell.execute_reply.started":"2023-10-04T04:59:58.296366Z","shell.execute_reply":"2023-10-04T04:59:58.304485Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"%ls -a","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:58.307159Z","iopub.execute_input":"2023-10-04T04:59:58.307627Z","iopub.status.idle":"2023-10-04T04:59:59.378554Z","shell.execute_reply.started":"2023-10-04T04:59:58.307594Z","shell.execute_reply":"2023-10-04T04:59:59.377050Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34m.\u001b[0m/  \u001b[01;34m..\u001b[0m/  \u001b[01;34m.virtual_documents\u001b[0m/  \u001b[01;34msegment-anything\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:59.380463Z","iopub.execute_input":"2023-10-04T04:59:59.381664Z","iopub.status.idle":"2023-10-04T04:59:59.417673Z","shell.execute_reply.started":"2023-10-04T04:59:59.381620Z","shell.execute_reply":"2023-10-04T04:59:59.416655Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"import monai","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:59.422331Z","iopub.execute_input":"2023-10-04T04:59:59.422893Z","iopub.status.idle":"2023-10-04T04:59:59.429006Z","shell.execute_reply.started":"2023-10-04T04:59:59.422856Z","shell.execute_reply":"2023-10-04T04:59:59.427939Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def resize(path):\n  dirs = os.listdir( path )\n  for item in tqdm(dirs):\n    if os.path.isfile(path+item):\n      im = Image.open(path+item)\n      f, e = os.path.splitext(path+item)\n      imResize = im.resize((1024,1024), Image.NEAREST)\n      imResize.save(f+e, 'PNG', quality=100)\n\nlabel_path =  \"/kaggle/input/nucleus-data/nucleus_data/segmentation_maps\"\noutput_features_path = \"/kaggle/input/nucleus-data/nucleus_data/features\"\nresize(label_path)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:59.430523Z","iopub.execute_input":"2023-10-04T04:59:59.431220Z","iopub.status.idle":"2023-10-04T05:00:03.443479Z","shell.execute_reply.started":"2023-10-04T04:59:59.431185Z","shell.execute_reply":"2023-10-04T05:00:03.442441Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 6790/6790 [00:03<00:00, 1806.95it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"ids=[]\nlabel_filenames = [f for f in listdir(label_path) if isfile(join(label_path, f))]\nfeature_filenames = [f for f in listdir(output_features_path) if isfile(join(output_features_path, f))]\nfor i in range(len(feature_filenames)):\n  ids.append(feature_filenames[i][1:])\nprint(len(ids))\n\ndf = pd.DataFrame(ids ,columns=[\"file_ids\"])\ndf.to_csv('full_file_ids.csv', index=False)\n\n#sanity check\ndf = pd.read_csv('full_file_ids.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:00:03.444962Z","iopub.execute_input":"2023-10-04T05:00:03.445933Z","iopub.status.idle":"2023-10-04T05:00:22.359031Z","shell.execute_reply.started":"2023-10-04T05:00:03.445896Z","shell.execute_reply":"2023-10-04T05:00:22.358055Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"6756\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"     file_ids\n0  182_22.png\n1  167_27.png\n2   86_29.png\n3  154_16.png\n4   177_8.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>182_22.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>167_27.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>86_29.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154_16.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>177_8.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport os\nimport cv2\n\ndf = pd.read_csv('full_file_ids.csv')\nids = df['file_ids'].tolist()\nnon_empty_ids = []\n\nfor file_id in ids:\n    mask_path = os.path.join(label_path, 'L' + file_id)\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    if cv2.countNonZero(mask) > 0:\n        non_empty_ids.append(file_id)\n\ndf_non_empty = pd.DataFrame(non_empty_ids, columns=[\"file_ids\"])\ndf_non_empty.sort_values(by='file_ids', inplace=True)  # Sort the DataFrame by 'file_ids'\ndf_non_empty.to_csv('file_ids.csv', index=False)\n\n\ndif = pd.read_csv('file_ids.csv')\ndif.head(15)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:00:22.360482Z","iopub.execute_input":"2023-10-04T05:00:22.361377Z","iopub.status.idle":"2023-10-04T05:00:54.596798Z","shell.execute_reply.started":"2023-10-04T05:00:22.361342Z","shell.execute_reply":"2023-10-04T05:00:54.595855Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"      file_ids\n0     0_10.png\n1     0_11.png\n2     0_12.png\n3     0_13.png\n4     0_14.png\n5     0_15.png\n6     0_16.png\n7     0_17.png\n8     0_18.png\n9     0_19.png\n10    0_20.png\n11    0_21.png\n12    0_22.png\n13  100_10.png\n14  100_11.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0_10.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0_11.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0_12.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0_13.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0_14.png</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0_15.png</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0_16.png</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0_17.png</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0_18.png</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0_19.png</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0_20.png</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0_21.png</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0_22.png</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>100_10.png</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>100_11.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, csv_file, bbox_shift=20):\n        self.df = pd.read_csv(csv_file)\n        self.ids = self.df[\"file_ids\"]\n        self.img_path = \"/kaggle/input/nucleus-data/nucleus_data/features/\"\n        self.mask_path = \"/kaggle/input/nucleus-data/nucleus_data/segmentation_maps/\"\n        self.bbox_shift = bbox_shift\n        print(f\"number of images: {len(self.ids)}\")\n\n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, index):\n        # Load image and mask using the ID from the CSV\n        img_name = f\"F{self.ids[index]}\"\n        mask_name = f\"L{self.ids[index]}\"\n\n        # Load and resize image to 1024x1024, then convert to RGB\n        img = Image.open(join(self.img_path, img_name)).resize((1024, 1024)).convert(\"RGB\")\n        img = np.array(img)  # Convert image to numpy array\n\n        img = img / 255.0\n\n        # Load and resize mask to 1024x1024\n        mask = Image.open(join(self.mask_path, mask_name)).resize((1024, 1024))\n        mask = np.array(mask)  # Convert mask to numpy array\n\n        # Convert the shape to (3, H, W) for image and (1, H, W) for mask\n        img = np.transpose(img, (2, 0, 1))\n        mask = np.expand_dims(mask, axis=0)  # Add an extra dimension for the channel\n\n        label_ids = np.unique(mask)[1:]\n        mask_binary = np.uint8(mask == random.choice(label_ids.tolist()))[1]  # only one label, (1024, 1024)\n\n\n        y_indices, x_indices = np.where(mask_binary > 0)\n        x_min, x_max = np.min(x_indices), np.max(x_indices)\n        y_min, y_max = np.min(y_indices), np.max(y_indices)\n        # add perturbation to bounding box coordinates\n        H, W = mask_binary.shape\n        x_min = max(0, x_min - random.randint(0, self.bbox_shift))\n        x_max = min(W, x_max + random.randint(0, self.bbox_shift))\n        y_min = max(0, y_min - random.randint(0, self.bbox_shift))\n        y_max = min(H, y_max + random.randint(0, self.bbox_shift))\n        bboxes = np.array([x_min, y_min, x_max, y_max])\n\n        return (\n            torch.tensor(img).float(),\n            torch.tensor(mask_binary[None, :, :]).long(),\n            torch.tensor(bboxes).float(),\n            img_name,\n        )\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:00:54.598562Z","iopub.execute_input":"2023-10-04T05:00:54.599311Z","iopub.status.idle":"2023-10-04T05:00:54.611055Z","shell.execute_reply.started":"2023-10-04T05:00:54.599274Z","shell.execute_reply":"2023-10-04T05:00:54.610017Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"%mkdir checkpoint_save\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:21.683552Z","iopub.execute_input":"2023-10-04T06:01:21.683961Z","iopub.status.idle":"2023-10-04T06:01:22.808293Z","shell.execute_reply.started":"2023-10-04T06:01:21.683928Z","shell.execute_reply":"2023-10-04T06:01:22.806999Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘checkpoint_save’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"lr=0.0001\nbatch_size = 4\ndata_path = \"/kaggle/input/nucleus-data/nucleus_data\"\ncheckpoint = \"/kaggle/working/sam_vit_b_01ec64.pth\"\nmodel_type = \"vit_b\"\nwork_dir = \"/kaggle/working/checkpoint_save\"\nnum_epochs = 10\nnum_workers=0\nuse_wandb = 1\nuse_amp = 0\nresume = \"\"\ntask_name = \"CellSAM-ViT-B\"\nnum_epochs = num_epochs\niter_num = 0\nstart_epoch = 0\nlosses = []\nbest_loss = 1e10","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:22.811459Z","iopub.execute_input":"2023-10-04T06:01:22.815237Z","iopub.status.idle":"2023-10-04T06:01:22.824231Z","shell.execute_reply.started":"2023-10-04T06:01:22.815190Z","shell.execute_reply":"2023-10-04T06:01:22.822925Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"os.makedirs(work_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:22.825622Z","iopub.execute_input":"2023-10-04T06:01:22.826193Z","iopub.status.idle":"2023-10-04T06:01:22.841055Z","shell.execute_reply.started":"2023-10-04T06:01:22.826159Z","shell.execute_reply":"2023-10-04T06:01:22.840025Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Instantiate your dataset\ntr_dataset = SegmentationDataset(csv_file='file_ids.csv',)\ntr_dataloader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True)\n\ndef show_mask(mask, ax, random_color=False):\n    if random_color:\n        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n    else:\n        color = np.array([251 / 255, 252 / 255, 30 / 255, 0.6])\n    h, w = mask.shape[-2:]\n    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n    ax.imshow(mask_image)\n\ndef show_box(box, ax):\n    x0, y0 = box[0], box[1]\n    w, h = box[2] - box[0], box[3] - box[1]\n    ax.add_patch(\n        plt.Rectangle((x0, y0), w, h, edgecolor=\"blue\", facecolor=(0, 0, 0, 0), lw=2)\n    )\n\nfor step, (image, mask_binary, bboxes, img_name) in enumerate(tr_dataloader):\n    print(image.shape, mask_binary.shape, bboxes.shape)\n    # show the example\n    _, axs = plt.subplots(1, 2, figsize=(25, 25))\n    idx = random.randint(0, image.size(0) - 1)  # Update this line to get a valid index\n    axs[0].imshow(image[idx].cpu().permute(1, 2, 0).numpy())\n    show_mask(mask_binary[idx].cpu().numpy()[0], axs[0])  # Passing the 2D mask to show_mask\n    show_box(bboxes[idx].numpy(), axs[0])\n    axs[0].axis(\"off\")\n    # set title\n    axs[0].set_title(img_name[idx])\n    idx = random.randint(0, image.size(0) - 1)  # Update this line to get a valid index\n    axs[1].imshow(image[idx].cpu().permute(1, 2, 0).numpy())\n    show_mask(mask_binary[idx].cpu().numpy()[0], axs[1])  # Passing the 2D mask to show_mask\n    show_box(bboxes[idx].numpy(), axs[1])\n    axs[1].axis(\"off\")\n    # set title\n    axs[1].set_title(img_name[idx])\n    # plt.show()\n    plt.subplots_adjust(wspace=0.01, hspace=0)\n    plt.savefig(\"./data_sanitycheck.png\", bbox_inches=\"tight\", dpi=300)\n    plt.close()\n    break\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:22.844150Z","iopub.execute_input":"2023-10-04T06:01:22.844776Z","iopub.status.idle":"2023-10-04T06:01:33.703755Z","shell.execute_reply.started":"2023-10-04T06:01:22.844745Z","shell.execute_reply":"2023-10-04T06:01:33.702502Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"number of images: 4978\ntorch.Size([4, 3, 1024, 1024]) torch.Size([4, 1, 1024, 1024]) torch.Size([4, 4])\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:33.709072Z","iopub.execute_input":"2023-10-04T06:01:33.711963Z","iopub.status.idle":"2023-10-04T06:01:36.523772Z","shell.execute_reply.started":"2023-10-04T06:01:33.711926Z","shell.execute_reply":"2023-10-04T06:01:36.522451Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"--2023-10-04 06:01:34--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.164.78.81, 18.164.78.72, 18.164.78.121, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.164.78.81|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 375042383 (358M) [binary/octet-stream]\nSaving to: ‘sam_vit_b_01ec64.pth.1’\n\nsam_vit_b_01ec64.pt 100%[===================>] 357.67M   223MB/s    in 1.6s    \n\n2023-10-04 06:01:36 (223 MB/s) - ‘sam_vit_b_01ec64.pth.1’ saved [375042383/375042383]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class CellSAM(nn.Module):\n    def __init__(\n        self,\n        image_encoder,\n        mask_decoder,\n        prompt_encoder,\n    ):\n        super().__init__()\n        self.image_encoder = image_encoder\n        self.mask_decoder = mask_decoder\n        self.prompt_encoder = prompt_encoder\n        # freeze prompt encoder\n\n        for param in self.prompt_encoder.parameters():\n            param.requires_grad = False\n\n        for param in self.image_encoder.parameters():\n            param.requires_grad = False\n\n    def forward(self, image, box):\n        image_embedding = self.image_encoder(image)  # (B, 256, 64, 64)\n        # do not compute gradients for prompt encoder\n        with torch.no_grad():\n            box_torch = torch.as_tensor(box, dtype=torch.float32, device=image.device)\n            if len(box_torch.shape) == 2:\n                box_torch = box_torch[:, None, :]  # (B, 1, 4)\n\n            sparse_embeddings, dense_embeddings = self.prompt_encoder(\n                points=None,\n                boxes=box_torch,\n                masks=None,\n            )\n\n\n        low_res_masks, iou_predictions = self.mask_decoder(\n            image_embeddings=image_embedding,  # (B, 256, 64, 64)\n            image_pe=self.prompt_encoder.get_dense_pe(),  # (1, 256, 64, 64)\n            sparse_prompt_embeddings=sparse_embeddings,  # (B, 2, 256)\n            dense_prompt_embeddings=dense_embeddings,  # (B, 256, 64, 64)\n            multimask_output=False,\n        )\n        ori_res_masks = F.interpolate(\n            low_res_masks,\n            size=(image.shape[2], image.shape[3]),\n            mode=\"bilinear\",\n            align_corners=False,\n        )\n        return ori_res_masks","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:36.525703Z","iopub.execute_input":"2023-10-04T06:01:36.526361Z","iopub.status.idle":"2023-10-04T06:01:36.542377Z","shell.execute_reply.started":"2023-10-04T06:01:36.526324Z","shell.execute_reply":"2023-10-04T06:01:36.541400Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"ls -a\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:36.543449Z","iopub.execute_input":"2023-10-04T06:01:36.544654Z","iopub.status.idle":"2023-10-04T06:01:37.647876Z","shell.execute_reply.started":"2023-10-04T06:01:36.544619Z","shell.execute_reply":"2023-10-04T06:01:37.646583Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34m.\u001b[0m/                   data_sanitycheck.png  sam_vit_b_01ec64.pth.1\n\u001b[01;34m..\u001b[0m/                  file_ids.csv          \u001b[01;34msegment-anything\u001b[0m/\n\u001b[01;34m.virtual_documents\u001b[0m/  full_file_ids.csv     \u001b[01;34mwandb\u001b[0m/\n\u001b[01;34mcheckpoint_save\u001b[0m/     sam_vit_b_01ec64.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"model = sam_model_registry[model_type](checkpoint=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:37.649710Z","iopub.execute_input":"2023-10-04T06:01:37.650590Z","iopub.status.idle":"2023-10-04T06:01:38.905657Z","shell.execute_reply.started":"2023-10-04T06:01:37.650546Z","shell.execute_reply":"2023-10-04T06:01:38.904502Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"cellsam_model = CellSAM(\n        image_encoder=model.image_encoder,\n        mask_decoder=model.mask_decoder,\n        prompt_encoder=model.prompt_encoder,\n    ).to(device)\n\ncellsam_model.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:38.907178Z","iopub.execute_input":"2023-10-04T06:01:38.911635Z","iopub.status.idle":"2023-10-04T06:01:39.032951Z","shell.execute_reply.started":"2023-10-04T06:01:38.911593Z","shell.execute_reply":"2023-10-04T06:01:39.031886Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"CellSAM(\n  (image_encoder): ImageEncoderViT(\n    (patch_embed): PatchEmbed(\n      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (blocks): ModuleList(\n      (0-11): 12 x Block(\n        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n          (proj): Linear(in_features=768, out_features=768, bias=True)\n        )\n        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): MLPBlock(\n          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n          (act): GELU(approximate='none')\n        )\n      )\n    )\n    (neck): Sequential(\n      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): LayerNorm2d()\n      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (3): LayerNorm2d()\n    )\n  )\n  (mask_decoder): MaskDecoder(\n    (transformer): TwoWayTransformer(\n      (layers): ModuleList(\n        (0-1): 2 x TwoWayAttentionBlock(\n          (self_attn): Attention(\n            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n          )\n          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (cross_attn_token_to_image): Attention(\n            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n          )\n          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (mlp): MLPBlock(\n            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n            (act): ReLU()\n          )\n          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          (cross_attn_image_to_token): Attention(\n            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n          )\n        )\n      )\n      (final_attn_token_to_image): Attention(\n        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n      )\n      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    )\n    (iou_token): Embedding(1, 256)\n    (mask_tokens): Embedding(4, 256)\n    (output_upscaling): Sequential(\n      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n      (1): LayerNorm2d()\n      (2): GELU(approximate='none')\n      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n      (4): GELU(approximate='none')\n    )\n    (output_hypernetworks_mlps): ModuleList(\n      (0-3): 4 x MLP(\n        (layers): ModuleList(\n          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n          (2): Linear(in_features=256, out_features=32, bias=True)\n        )\n      )\n    )\n    (iou_prediction_head): MLP(\n      (layers): ModuleList(\n        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n        (2): Linear(in_features=256, out_features=4, bias=True)\n      )\n    )\n  )\n  (prompt_encoder): PromptEncoder(\n    (pe_layer): PositionEmbeddingRandom()\n    (point_embeddings): ModuleList(\n      (0-3): 4 x Embedding(1, 256)\n    )\n    (not_a_point_embed): Embedding(1, 256)\n    (mask_downscaling): Sequential(\n      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n      (1): LayerNorm2d()\n      (2): GELU(approximate='none')\n      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n      (4): LayerNorm2d()\n      (5): GELU(approximate='none')\n      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (no_mask_embed): Embedding(1, 256)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"print(\n        \"Number of total parameters: \",\n        sum(p.numel() for p in cellsam_model.parameters()),\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.038320Z","iopub.execute_input":"2023-10-04T06:01:39.039134Z","iopub.status.idle":"2023-10-04T06:01:39.049570Z","shell.execute_reply.started":"2023-10-04T06:01:39.039092Z","shell.execute_reply":"2023-10-04T06:01:39.047327Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Number of total parameters:  93735472\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\n        \"Number of trainable parameters: \",\n        sum(p.numel() for p in cellsam_model.parameters() if p.requires_grad),\n\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.053044Z","iopub.execute_input":"2023-10-04T06:01:39.053365Z","iopub.status.idle":"2023-10-04T06:01:39.072645Z","shell.execute_reply.started":"2023-10-04T06:01:39.053296Z","shell.execute_reply":"2023-10-04T06:01:39.071427Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Number of trainable parameters:  4058340\n","output_type":"stream"}]},{"cell_type":"code","source":"img_mask_encdec_params = cellsam_model.mask_decoder.parameters()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.074318Z","iopub.execute_input":"2023-10-04T06:01:39.074872Z","iopub.status.idle":"2023-10-04T06:01:39.084921Z","shell.execute_reply.started":"2023-10-04T06:01:39.074840Z","shell.execute_reply":"2023-10-04T06:01:39.083922Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(\n        img_mask_encdec_params, lr=0.0001, weight_decay=0.01\n    )\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.085943Z","iopub.execute_input":"2023-10-04T06:01:39.087369Z","iopub.status.idle":"2023-10-04T06:01:39.100028Z","shell.execute_reply.started":"2023-10-04T06:01:39.087338Z","shell.execute_reply":"2023-10-04T06:01:39.099028Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"seg_loss = monai.losses.DiceLoss(sigmoid=True, squared_pred=True, reduction=\"mean\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.104778Z","iopub.execute_input":"2023-10-04T06:01:39.105539Z","iopub.status.idle":"2023-10-04T06:01:39.115205Z","shell.execute_reply.started":"2023-10-04T06:01:39.105503Z","shell.execute_reply":"2023-10-04T06:01:39.113850Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"ce_loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.117140Z","iopub.execute_input":"2023-10-04T06:01:39.117480Z","iopub.status.idle":"2023-10-04T06:01:39.129437Z","shell.execute_reply.started":"2023-10-04T06:01:39.117445Z","shell.execute_reply":"2023-10-04T06:01:39.128135Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"print(\"Number of training samples: \", len(tr_dataset))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.133805Z","iopub.execute_input":"2023-10-04T06:01:39.136021Z","iopub.status.idle":"2023-10-04T06:01:39.149865Z","shell.execute_reply.started":"2023-10-04T06:01:39.135958Z","shell.execute_reply":"2023-10-04T06:01:39.148694Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Number of training samples:  4978\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q wandb","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:39.151775Z","iopub.execute_input":"2023-10-04T06:01:39.153213Z","iopub.status.idle":"2023-10-04T06:01:49.449326Z","shell.execute_reply.started":"2023-10-04T06:01:39.153172Z","shell.execute_reply":"2023-10-04T06:01:49.447867Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"if use_wandb:\n    import wandb\n\n    wandb.login()\n    wandb.init(\n        project= task_name,\n        config={\n            \"lr\": lr,\n            \"batch_size\": batch_size,\n            \"data_path\": data_path,\n            \"model_type\": model_type,\n        },\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:01:49.451524Z","iopub.execute_input":"2023-10-04T06:01:49.452187Z","iopub.status.idle":"2023-10-04T06:02:24.235694Z","shell.execute_reply.started":"2023-10-04T06:01:49.452146Z","shell.execute_reply":"2023-10-04T06:02:24.234731Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:g1iidazp) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b812351052b4e29946fda6f6b6e08b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_loss</td><td>0.98063</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">atomic-sun-37</strong> at: <a href='https://wandb.ai/roadname/CellSAM-ViT-B/runs/g1iidazp' target=\"_blank\">https://wandb.ai/roadname/CellSAM-ViT-B/runs/g1iidazp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20231004_050158-g1iidazp/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:g1iidazp). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.11 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231004_060149-689g48ru</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/roadname/CellSAM-ViT-B/runs/689g48ru' target=\"_blank\">rosy-bee-38</a></strong> to <a href='https://wandb.ai/roadname/CellSAM-ViT-B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/roadname/CellSAM-ViT-B' target=\"_blank\">https://wandb.ai/roadname/CellSAM-ViT-B</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/roadname/CellSAM-ViT-B/runs/689g48ru' target=\"_blank\">https://wandb.ai/roadname/CellSAM-ViT-B/runs/689g48ru</a>"},"metadata":{}}]},{"cell_type":"code","source":"run_id = datetime.now().strftime(\"%Y%m%d-%H%M\")\nmodel_save_path = join(work_dir, task_name + \"-\" + run_id)\ndevice = torch.device(device)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:02:24.239851Z","iopub.execute_input":"2023-10-04T06:02:24.241938Z","iopub.status.idle":"2023-10-04T06:02:24.248608Z","shell.execute_reply.started":"2023-10-04T06:02:24.241904Z","shell.execute_reply":"2023-10-04T06:02:24.247610Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"os.makedirs(model_save_path, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:02:24.252963Z","iopub.execute_input":"2023-10-04T06:02:24.255347Z","iopub.status.idle":"2023-10-04T06:02:24.265001Z","shell.execute_reply.started":"2023-10-04T06:02:24.255311Z","shell.execute_reply":"2023-10-04T06:02:24.264092Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"if resume is not None:\n    if os.path.isfile(resume):\n        checkpoint = torch.load(resume, map_location=device)\n        start_epoch = checkpoint[\"epoch\"] + 1\n        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\nif use_amp:\n    scaler = torch.cuda.amp.GradScaler()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:02:24.269277Z","iopub.execute_input":"2023-10-04T06:02:24.270023Z","iopub.status.idle":"2023-10-04T06:02:24.281162Z","shell.execute_reply.started":"2023-10-04T06:02:24.269961Z","shell.execute_reply":"2023-10-04T06:02:24.279936Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"gpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n  print('Not connected to a GPU')\nelse:\n  print(gpu_info)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:02:24.284126Z","iopub.execute_input":"2023-10-04T06:02:24.285720Z","iopub.status.idle":"2023-10-04T06:02:24.349698Z","shell.execute_reply.started":"2023-10-04T06:02:24.285687Z","shell.execute_reply":"2023-10-04T06:02:24.348771Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Wed Oct  4 06:02:24 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   41C    P0    32W / 250W |  12421MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"from psutil import virtual_memory\nram_gb = virtual_memory().total / 1e9\nprint('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n\nif ram_gb < 20:\n  print('Not using a high-RAM runtime')\nelse:\n  print('You are using a high-RAM runtime!')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:02:24.353701Z","iopub.execute_input":"2023-10-04T06:02:24.354086Z","iopub.status.idle":"2023-10-04T06:02:24.366759Z","shell.execute_reply.started":"2023-10-04T06:02:24.354052Z","shell.execute_reply":"2023-10-04T06:02:24.365814Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Your runtime has 16.8 gigabytes of available RAM\n\nNot using a high-RAM runtime\n","output_type":"stream"}]},{"cell_type":"code","source":"    for epoch in range(start_epoch, num_epochs):\n        epoch_loss = 0\n        for step, (image, gt2D, boxes, _) in enumerate(tqdm(tr_dataloader)):\n            optimizer.zero_grad()\n            boxes_np = boxes.detach().cpu().numpy()\n            image, gt2D = image.to(device), gt2D.to(device)\n            if use_amp:\n                ## AMP\n                with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n                    cellsam_pred = cellsam_model(image, boxes_np)\n                    loss = seg_loss(cellsam_pred, gt2D) + ce_loss(\n                        cellsam_pred, gt2D.float()\n                    )\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n            else:\n                cellsam_pred = cellsam_model(image,boxes_np)\n                loss = seg_loss(cellsam_pred, gt2D) + ce_loss(cellsam_pred, gt2D.float())\n                loss.backward()\n                optimizer.step()\n                optimizer.zero_grad()\n\n            epoch_loss += loss.item()\n            iter_num += 1\n\n        epoch_loss /= step\n        losses.append(epoch_loss)\n        if use_wandb:\n            wandb.log({\"epoch_loss\": epoch_loss})\n        print(\n            f'Time: {datetime.now().strftime(\"%Y%m%d-%H%M\")}, Epoch: {epoch}, Loss: {epoch_loss}'\n        )\n        ## save the latest model\n        checkpoint = {\n            \"model\": cellsam_model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n            \"epoch\": epoch,\n        }\n        torch.save(checkpoint, join(model_save_path, \"cellsam_model_latest.pth\"))\n        ## save the best model\n        if epoch_loss < best_loss:\n            best_loss = epoch_loss\n            checkpoint = {\n                \"model\": cellsam_model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"epoch\": epoch,\n            }\n            torch.save(checkpoint, join(model_save_path, \"cellsam_model_best.pth\"))\n\n        # %% plot loss\n        plt.plot(losses)\n        plt.title(\"Dice + Cross Entropy Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.savefig(join(model_save_path, task_name + \"train_loss.png\"))\n        plt.close()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:02:24.368599Z","iopub.execute_input":"2023-10-04T06:02:24.370378Z","iopub.status.idle":"2023-10-04T10:26:05.393323Z","shell.execute_reply.started":"2023-10-04T06:02:24.370343Z","shell.execute_reply":"2023-10-04T10:26:05.392169Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stderr","text":"100%|██████████| 1245/1245 [26:25<00:00,  1.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0628, Epoch: 0, Loss: 0.9797209558283785\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:13<00:00,  1.26s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0655, Epoch: 1, Loss: 0.973245225104105\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:19<00:00,  1.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0721, Epoch: 2, Loss: 0.9697802496588882\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:17<00:00,  1.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0747, Epoch: 3, Loss: 0.9685803066783396\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:13<00:00,  1.26s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0814, Epoch: 4, Loss: 0.969251671021391\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:14<00:00,  1.26s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0840, Epoch: 5, Loss: 0.9672019827116723\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:22<00:00,  1.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0906, Epoch: 6, Loss: 0.9664490674277977\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:21<00:00,  1.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0933, Epoch: 7, Loss: 0.9657802456253212\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:27<00:00,  1.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-0959, Epoch: 8, Loss: 0.9649513142476894\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1245/1245 [26:18<00:00,  1.27s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20231004-1026, Epoch: 9, Loss: 0.966124671975516\n","output_type":"stream"}]}]}